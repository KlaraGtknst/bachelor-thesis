\section{\acl{ae}}\label{subsec:impl-autoencoder}

In this work, the \ac{ae} is used to reduce the dimensionality of the \infersent{} embedding.
Since the \infersent{} model is pretrained, it is not possible to change the dimensionality of the embedding without a considerably big effort,
i.e. retraining the model on a sufficiently large data corpus and reconfiguring the model's parameters.
Moreover, retraining the model would destroy the purpose of its presence in this work, which is to provide a pretrained model and thus, 
reducing the complexity of training an own model.
Therefore, it is not feasible to change the dimensionality of the \infersent{} embedding, but rather adding a supplementary layer after the model 
produce the final embedding.
Hence, the idea is to use the encoder of an \ac{ae} to reduce the dimensionality of the \infersent{} embedding.

The implementation was provided by 
\href{https://blog.paperspace.com/autoencoder-image-compression-keras/}{a blog post using keras}
and adapted to fulfil the needs of the specific context.
Hence, The dimensionality of the layers was increased since the \ac{ae} of the blog post has a smaller dimensionality in the latent space.
More layers were added to the encoder and decoder to improve the ability of the model to reconstruct.
\autoref{fig:impl-encoder} \autoref{fig:impl-ae}

\begin{figure}[h] % htp = hier (h), top (t), oder auf einer eigenen Seite (p).
    \centering
    \includesvg[width=0.6\textwidth]{images/compression/autoencoder/encoder-impl.svg}
    \caption{Architecture of the encoder of the \ac{ae}}
    \label{fig:impl-encoder}
\end{figure}

\begin{figure}[h] % htp = hier (h), top (t), oder auf einer eigenen Seite (p).
    \centering
    \includesvg[width=1.0\textwidth]{images/compression/autoencoder/autoencoder-impl.svg}
    \caption{Architecture of the \ac{ae}}
    \label{fig:impl-ae}
\end{figure}