\section{Preprocessing}\label{sec:preprocessing}

Similar to other \ac{ml} domains, \ac{nlp} requires preprocessing of the data.
Usually, textual data contains irrelevant information and noise.
Examples of noise include so-called stop words, such as "the" or "and".
However, irrelevant information can be task-specific. 
In some cases, numerical data may be regarded to be irrelevant and should be omitted.
Preprocessing improves the performance and the results \cite{clusteringDocs2020}.
The next sections describe the non-trivial preprocessing steps applied in this work.


\subsection{Tokenization}\label{subsec:tokenization}

\begin{figure}[!htp] % htp = hier (h), top (t), oder auf einer eigenen Seite (p).
    \centering
    \includesvg[width=0.7\textwidth]{images/preprocessing/Preproc-tokenization.svg}
    \caption[Tokenization]{Tokenization visualized using an example text.}
    \label{fig:preproc-tokenization}
\end{figure}

\textit{Tokenization} is the process of splitting a text into smaller pieces, so-called \textit{tokens}.
Tokens can be words and punctuation marks \cite{nlp-book2009}.
The definition of a token depends on the application.
For instance, certain tokenization implementations may identify tokens as subsequent series of non-whitespace characters omitting all numbers and punctuation marks \cite{IR2011}.


% \textit{Chunking} is the process of splitting a text into smaller pieces, so-called \textit{chunks}.
% A chunk is a sequence of tokens, e.g. words, in a text \cite{nlp-book2009}.
% Chunks do not overlap.
% According to \citeauthor{nlp-book2009}, chunkers produce their pieces by following a set of rules, e.g., grammar rules.


\subsection{\stopWordRemoval{}}\label{subsec:stop-word-removal}

\begin{figure}[!htp] % htp = hier (h), top (t), oder auf einer eigenen Seite (p).
    \centering
    \includesvg[width=0.7\textwidth]{images/preprocessing/Preprocessing-stop-word-removal.svg}
    \caption[\stopWordRemoval{}]{\stopWordRemoval{} visualized using an example text.}
    \label{fig:preproc-stop-word-removal}
\end{figure}

Omitting words that are not relevant to the context of the text is called \textit{stop-word-removal}.
Stop words not only depend on the domain but also the language \cite{IR2011}.


\subsection{Stemming}\label{subsec:stemming}

In order to avoid language inflections, i.e.\ treating words with similar meanings differently, stemming is applied \cite{clusteringDocs2020}.
According to \citeauthor{nlp-book2009}, \textit{stemming} is the process of stripping off any affixes, i.e.\ prefixes and suffixes \cite{IR2011}, 
from a word and returning the stem.
Different types of stemmers are better suited for certain applications than others.
Hence, the choice of the stemmer depends on the application.

% For instance, the \textit{Porter Stemmer} performs well for English texts \cite{nlp-book2009, clusteringDocs2020}.
% It is predominantly used for the normalization of inflected forms.
% The \textit{Porter Stemmer} is an algorithmic stemmer, 
% i.e.\ it applies a set of rules to a word to produce the stem and thus, does not use a dictionary \cite{IR2011, clusteringDocs2020}.


\subsection{\Lemmatization{}}\label{subsec:lemmatization}

\begin{figure}[!htp] % htp = hier (h), top (t), oder auf einer eigenen Seite (p).
    \centering
    \includesvg[width=0.7\textwidth]{images/preprocessing/Preprocessing-lemmatization.svg}
    \caption[\Lemmatization{}]{\Lemmatization{} visualized using an example text.}
    \label{fig:preproc-lemmatization}
\end{figure}

Stemming and lemmatization are used to reduce the vocabulary size \cite{clusteringDocs2020}.
Opposed to stemming, lemmatization returns only stems that are considered valid words \cite{nlp-book2009}.
Some implementations of lemmatizers validate stems with regard to a set of valid words, i.e.\ \textit{lemma}s, stored in a dictionary.
Lemmatizers are usually slower than stemmers \cite{nlp-book2009}.

The \textit{WordNetLemmatizer} from the \texttt{nltk} package\footnote{https://www.nltk.org/\_modules/nltk/stem/wordnet.html (last accessed: 12/11/2023)} requires a vocabulary. % \cite{clusteringDocs2020}.
According to \citeauthor{clusteringDocs2020}, it is frequently used for lemmatization of English texts \cite{clusteringDocs2020}.
%It considers not only the meaning of words but also the order of the words \cite{clusteringDocs2020}.


% \subsection{Lower case}\label{subsec:lower-case}

% Words with capital letters are converted to lowercase.