\chapter{Methodology}\label{ch:methodology}

\cite{InformationRetrieval1999}

Basic concepts, methods used, etc.

\section{Preprocessing}\label{sec:preprocessing}

\subsection{Tokenization/ Chunking}\label{subsec:tokenization}

\subsection{Lemmatization}\label{subsec:lemmatization}
Type of Stemmers. Porter, Snowball, Lancaster, etc.
% https://databasecamp.de/daten/stemming-lemmatizations for difference betwee stemmers and lemmatizers
Pre-trained/defined dense vector dictionaries (Word2Vec, \ac{glove}, FastText, etc.)

\subsection{Stop-Word-Removal}\label{subsec:stop-word-removal}

\subsection{Lower case}\label{subsec:lower-case}


\section{Similarity Measurement}\label{sec:similarity-measurement}

\cite{EmbDist2015}

\subsection{Cosine Similarity}\label{subsec:cosine-similarity}

\subsection{Soft Cosine Similarity}\label{subsec:soft-cosine-similarity}

\subsection{eucledian distance}\label{subsec:eucledian-distance}

\subsection{Hamming distance}\label{subsec:hamming-distance}

\subsection{\ac{wmd}}\label{subsec:word-mover-distance}

\subsection{SpaCy}\label{subsec:spacy}


\section{Embeddings}\label{sec:embeddings}

\cite{WordRep2013}
\cite{SentRep2014}

\textcolor{red}{Skizze von Pipeline f√ºr jedes Embedding, welche zeigt, wie die Daten vorverarbeitet (stemming etc.) werden/ was das Model selber macht.}

\subsection{\ac{cbow}}\label{subsec:bag-of-words}

\subsection{\ac{d2v}}\label{subsec:doc2vec}

\subsection{\ac{bertopic}}\label{subsec:bertopic}

\subsection{\ac{w2v}}\label{subsec:word2vec}

\subsection{\ac{tfidf}}\label{subsec:tfidf}
Test test test
% svg does not icons
\begin{figure}[h] % htp = hier (h), top (t), oder auf einer eigenen Seite (p).
    \centering
    \includegraphics[width=1.0\textwidth]{images/TFIDF_embedding}
    \caption{TFIDF Preprocessing}
    \label{fig:tfidf_embedding}
\end{figure}

\subsection{Universal sentence encoder}\label{subsec:univ-sent-encoder}
\cite{UniversalSentEnc2018}

\subsection{InferSent}\label{subsec:inferSent}
\cite{inferSent2018}

\subsection{Hugging face's sentence Transformers}\label{subsec:hf-sent-ransformers}

\subsection{One Hot Encoding}\label{subsec:one-hot-encoding}

\subsection{Skip Gram}\label{subsec:skip-gram}
\cite{SkipGram2013}

\subsection{FastText}\label{subsec:fasttext}

\subsection{Annoy}\label{subsec:glove}


\section{Topic Modelling}\label{sec:topic-modelling}

\subsection{\ac{lda}}\label{subsec:latent-dirichlet-allocation}

\subsection{Word Clouds}\label{subsec:word-clouds}
frequency of words in a document


\section{Appearance of documents}\label{sec:appearance}
documents saved as images in .png format, bad quality to minimize size of database
when querying db, top image results looked similar, which is how idea of this section arose

\subsection{AE}\label{subsec:autoencoder}

\subsection{eigenface}\label{subsec:eigenface}
like pca, but for images


