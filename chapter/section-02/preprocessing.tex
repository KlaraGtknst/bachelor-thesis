\section{Preprocessing}\label{sec:preprocessing}


\subsection{Tokenization/ Chunking}\label{subsec:tokenization}

\textit{Tokenization} is the process of splitting a text into smaller pieces, so-called \textit{tokens}.
Tokens can be words and punctuation marks \cite{nlp-book2009}.
However, the definition of a token depends on the application.
For instance, certain tokenization implementations may identify tokens as subsequent series of non-whitespace characters omitting all numbers and punctuation marks \cite{IR2011}.

\textit{Chunking} is the process of splitting a text into smaller pieces, so-called \textit{chunks}.
A chunk is a sequence of tokens, e.g. words, in a text \cite{nlp-book2009}.
Chunks do not overlap.
According to \citeauthor{nlp-book2009}, chunkers produce their pieces by following a set of rules, e.g., grammar rules.

\subsection{Stemming}\label{subsec:stemming}

According to \citeauthor{nlp-book2009}, \textit{stemming} is the process of striping off any affixes, i.e. prefixes and suffixes \cite{IR2011}, from a word and returning the stem.
Different types of stemmers are better suited for certain applications than others.
Hence, the choice of the stemmer depends on the application.
For instance, the \textit{Porter Stemmer} performs well when indexing texts and for text search using alternative forms, 
i.e. adding and omitting affixes, of words \cite{nlp-book2009}.
The \textit{Porter Stemmer} is a rule-based stemmer, i.e. it applies a set of rules to a word to produce the stem and thus, does not use a dictionary \cite{IR2011}.

\subsection{Lemmatization}\label{subsec:lemmatization}

By ensuring the resulting stem is a valid word, the process of stemming is called \textit{lemmatization} \cite{nlp-book2009}.
Some implementations of lemmatizers only stem words if the result is in its dictionary.
Since lemmatizers validate the result prior to returning it, they are usually slower than stemmers \cite{nlp-book2009}.


\subsection{Stop-Word-Removal}\label{subsec:stop-word-removal}

Omitting words that are not relevant to the context of the text is called \textit{stop-word-removal}.
Stop words not only depend on the domain but also on the language \cite{IR2011}.
Possibly, domain-specific stop-word lists are used to remove words that are not relevant to the context of the text \cite{IR2011}.



\subsection{Lower case}\label{subsec:lower-case}

Words with capital letters are converted to lowercase.