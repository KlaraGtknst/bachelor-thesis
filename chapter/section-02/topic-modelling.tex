\section{Topic Modelling}\label{sec:topic-modelling}

Since more and more text data emerges, methods to analyse and extract information from them become more important.
One of these methods is topic modelling.
It is used to discover groups of words with similar meanings in a text corpus \cite{topic_modeling2015}.
A topic is defined as a cluster of words that frequently occur together.
In other words, it is a probability distribution over a vocabulary.
Furthermore, a document is defined as a mixture of topics.
A document can thus be created by a distribution over topics and a distribution over words given the topics.
According to \citeauthor{topic_modeling2015}, topic models ignore the order of words in a document by relying on the bag-of-words assumption.
Common topic modelling algorithms are \ac{lsa}, \ac{plsa}, \ac{lda} and \ac{ctm} \cite{topic_modeling2015}.




\subsection{\ac{bertopic}}\label{subsec:bertopic}

\input{chapter/section-02/Top2Vec.tex}

\input{chapter/section-02/LDA.tex}


\subsection{Word Clouds}\label{subsec:word-clouds}

\textcolor{red}{eher implementation}
The size of a word correlates to its frequency or importance in the text.
However, a word does not have to be meaningful to appear large.
A word cloud does not provide information about the meaning or context of words and thus, 
one has to be careful when interpreting the results.
The implementation of word clouds in this thesis is based on the Python library \textit{wordcloud} \cite{wordcloud-dev}.
This implementation removes certain English stop words from the text by default.
The input text is split into tokens using a regex.
By default, plurals are removed if their singular version is present and their frequency is added to their singular version.
By default, numbers are not included as phrases/ tokens.