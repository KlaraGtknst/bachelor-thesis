\chapter{Experimental evaluation}\label{ch:evaluation}

Since the dataset has no ground truth the procedure used to pick the parameter values is not comparable to ground truth-based approaches.
Hence, the evaluation is informal and the methods applied have arisen from regular consultation with experts from the tax office.

 % Database
 \section{Database}\label{sec:eval-db}
There is a variety of parameter values to choose from when working with databases and embeddings.
These parameters include similarity metrics and the choice of queries.

 \input{chapter/section-05/eval-similarity-measurements.tex}

 \input{chapter/section-05/elasticsearch_db.tex}

 % Eigendocs
 \input{chapter/section-05/eval-eigendocs.tex}
 
 % Embeddings
\section{Embeddings}\label{sec:eval-embeddings}
As discussed in \autoref{subsec:impl-embeddings}, there is a range of possible parameter values to choose from when implementing embedding models.
The section below states which findings have led to the parameter values applied in this work.

\input{chapter/section-05/eval-tfidf.tex}

\input{chapter/section-05/eval-doc2vec.tex}

\input{chapter/section-05/eval-infersent.tex}

\input{chapter/section-05/eval-universal-sent-enc.tex}

\input{chapter/section-05/eval-autoencoder.tex}

% Clustering
\input{chapter/section-05/eval-optics.tex}





\section{Comparison of models}\label{sec:evaluation-models}

% parameters
Similar to \citeauthor{glove2014}'s work, in this work, for many models used, any unspecified parameters are set to their default values, 
assuming that they are close to optimal
acknowledging that this simplification should be revised in a more thorough analysis.

% comparing models (qualitative)
difference query responses for different models?
any images which produce unusual results?
